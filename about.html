<!DOCTYPE html>
<meta charset="utf-8">
<title>Stoplight üö¶ About</title>
<link href="https://fonts.googleapis.com/css?family=Work+Sans:300,400,600&display=swap" rel="stylesheet">
<meta name="viewport" content="width=device-width,initial-scale=1">
<link rel="stylesheet" type="text/css" href="style.css">
<body>
    <div class="textframe">
        <p><a href="index.html">‚Üê back</a></p>
        <h1>How</h1>
        <p>Untimed traffic lights usually detect cars using <a href="https://auto.howstuffworks.com/car-driving-safety/safety-regulatory-devices/how-does-a-traffic-light-detect-that-a-car-has-pulled-up-and-is-waiting-for-the-light-to-change.htm">a sensor in the pavement.</a> I‚Äôm pretty sure the one by my house uses a camera instead, pointed at the lane awaiting a green light:</p>

        <img class="about-image" src="assets/stoplightcamera.jpg">

        <p>I wonder if this sensor-signal-light loop is self-contained within the intersection. Does it operate unincluded from the carefully synchronized signal grid of the busier streets? Does it send a signal to anyone else, or does it talk to itself tracelessly? Even if I knew anything about circuitry, I‚Äôd go to jail trying to tap the sensor.</p>

        <p>(I fantasize about a city department control room that receives signal-changes from this light and all the lights in the city, like I half-remember seeing on a news station field trip as a kid. For a minute, I looked to see if these real time triggers were accessible anywhere by API. Some surprising data is public!)</p>

        <p>If I wanted to do this, I had to make my own sensor.</p>

        <p>I got <a href="https://apps.apple.com/us/app/ip-cam/id333208495#?platform=iphone">an app</a> that turns my old iPhone into a webcam. It can stream the video feed to anything on my wifi network, so I can embed it in a webpage, as long as I load it while I‚Äôm in my house. I taped the phone to my bedroom window:</p>

        <img class="about-image" src="assets/windowphone.jpg">

        <p>On the webpage that displays the phone video feed, I used <a href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/getImageData">a Javascript method</a> that gets the RGB pixel values from a section of the video feed frame. I highlighted a tiny crop where the clearest stoplight was visible:</p>

        <img class="about-image" src="assets/lights.png">

        <p>To me, the most interesting part was writing a test for these RGB values, quantifying ‚Äúdid this just turn red?‚Äù for every frame of this peephole. This is the closest I‚Äôve come to building anything related to computer vision. Every time this area turned sufficiently red, I recorded a timestamp. I ran it while I slept.</p>

        <p>My browser console output looks like:</p>

        <img class="about-image" src="assets/console.png">

        <p>Clean up with Find/Replace:</p>

        <img class="about-image" src="assets/lighttimes.png">

        <p>(The light that shines sideways into my bedroom signals the busier street. So while I tracked when the usually-green light turned red, note that I drew the chart in reverse, green turns onto a majority red, representing the light on the quieter street.)</p>

        <p>I use another Javascript file (using d3.js) to split each datetime up into its time (for the x-axis) and date (for the y-axis) and draw the chart with those coordinates. This is really just a scatterplot with long sticks instead of dots.</p>

        <p><a href="index.html">‚Üê back</a></p>

    </div>
</body>
